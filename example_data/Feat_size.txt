query
torch.Size([13449, 64])
torch.Size([3480, 128])
torch.Size([773, 256])
torch.Size([212, 512])
torch.Size([59, 1024])

positive
torch.Size([12944, 64])	torch.Size([12951, 64])
torch.Size([3331, 128])	torch.Size([3312, 128])
torch.Size([827, 256])		torch.Size([796, 256])
torch.Size([209, 512])		torch.Size([214, 512])
torch.Size([61, 1024])		torch.Size([58, 1024])

negative
torch.Size([14141, 64])	torch.Size([15344, 64])
torch.Size([3280, 128])	torch.Size([4006, 128])
torch.Size([763, 256])		torch.Size([1024, 256])
torch.Size([184, 512])		torch.Size([252, 512])
torch.Size([45, 1024])		torch.Size([67, 1024])

torch.Size([8296, 64])		torch.Size([4524, 64])
torch.Size([1868, 128])	torch.Size([977, 128])
torch.Size([462, 256])		torch.Size([241, 256])
torch.Size([121, 512])		torch.Size([63, 512])
torch.Size([27, 1024])		torch.Size([18, 1024])


FC_1.mlp.weight Parameter containing:
tensor([[ 0.0283, -0.0183,  0.0697,  ...,  0.1207,  0.1187,  0.0922],
        [ 0.0476,  0.0884, -0.0829,  ...,  0.0060, -0.0789, -0.0284],
        [-0.0739, -0.1159,  0.1244,  ..., -0.0216, -0.0243,  0.0014],
        ...,
        [ 0.1190, -0.1136,  0.1244,  ..., -0.0551, -0.1051,  0.0890],
        [-0.0371,  0.0401,  0.1133,  ..., -0.0327,  0.1247, -0.0487],
        [-0.0544,  0.0446, -0.1055,  ...,  0.0997, -0.0710,  0.0513]],
       device='cuda:0', requires_grad=True)
FC_1.batch_norm.bias Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
FC_2.mlp.weight Parameter containing:
tensor([[-0.0420, -0.0022,  0.0242,  ..., -0.0737, -0.0207, -0.0628],
        [-0.0200,  0.0375,  0.0299,  ...,  0.0562,  0.0492, -0.0373],
        [-0.0118, -0.0485,  0.0189,  ...,  0.0152,  0.0409,  0.0210],
        ...,
        [-0.0015,  0.0512, -0.0553,  ...,  0.0647,  0.0178,  0.0150],
        [ 0.0205, -0.0186,  0.0407,  ...,  0.0265, -0.0564,  0.0071],
        [-0.0480,  0.0523, -0.0593,  ...,  0.0293, -0.0786,  0.0447]],
       device='cuda:0', requires_grad=True)
FC_2.batch_norm.bias Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
FC_3.mlp.weight Parameter containing:
tensor([[-0.0040, -0.0171,  0.0456,  ...,  0.0058,  0.0109,  0.0081],
        [ 0.0535,  0.0097, -0.0314,  ..., -0.0527, -0.0408, -0.0496],
        [ 0.0091, -0.0610, -0.0261,  ...,  0.0341, -0.0579,  0.0189],
        ...,
        [ 0.0022,  0.0327, -0.0170,  ...,  0.0287, -0.0365, -0.0312],
        [-0.0275, -0.0348, -0.0521,  ..., -0.0539, -0.0186,  0.0191],
        [ 0.0496, -0.0101, -0.0620,  ..., -0.0385, -0.0436, -0.0389]],
       device='cuda:0', requires_grad=True)
FC_3.batch_norm.bias Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
FC_4.mlp.weight Parameter containing:
tensor([[-0.0259, -0.0078,  0.0394,  ...,  0.0251,  0.0013,  0.0366],
        [-0.0053,  0.0131,  0.0115,  ...,  0.0021, -0.0105, -0.0060],
        [ 0.0140,  0.0343,  0.0191,  ..., -0.0010, -0.0079, -0.0058],
        ...,
        [ 0.0183, -0.0176, -0.0425,  ..., -0.0076, -0.0191,  0.0060],
        [-0.0264, -0.0319, -0.0032,  ..., -0.0151,  0.0356,  0.0006],
        [-0.0025,  0.0063, -0.0237,  ...,  0.0438,  0.0016, -0.0036]],
       device='cuda:0', requires_grad=True)
FC_4.batch_norm.bias Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
vlad_layer.cluster_centers Parameter containing:
tensor([[-0.0184,  0.0024, -0.0044,  ..., -0.0069, -0.0157,  0.0566],
        [ 0.0265, -0.0759, -0.0114,  ..., -0.0046,  0.0135,  0.0025],
        [-0.0132,  0.0249, -0.0269,  ...,  0.0277,  0.0592,  0.0035],
        ...,
        [ 0.0098, -0.0131,  0.0014,  ..., -0.0013,  0.0149, -0.0233],
        [-0.0158, -0.0082, -0.0173,  ...,  0.0082, -0.0051, -0.0712],
        [ 0.0322,  0.0443, -0.0090,  ..., -0.0161,  0.0465,  0.0022]],
       device='cuda:0', requires_grad=True)
vlad_layer.FC_1.weight Parameter containing:
tensor([[ 0.0162,  0.0075,  0.0208,  ..., -0.0025,  0.0086,  0.0004],
        [ 0.0259,  0.0069,  0.0185,  ...,  0.0289,  0.0238, -0.0289],
        [ 0.0299,  0.0053,  0.0136,  ...,  0.0066, -0.0097,  0.0135],
        ...,
        [ 0.0153, -0.0227, -0.0275,  ...,  0.0146,  0.0302,  0.0060],
        [ 0.0134, -0.0171,  0.0211,  ...,  0.0113, -0.0166,  0.0233],
        [-0.0310, -0.0256, -0.0165,  ...,  0.0145, -0.0154,  0.0122]],
       device='cuda:0', requires_grad=True)
vlad_layer.FC_1.bias Parameter containing:
tensor([-0.0035, -0.0304, -0.0284, -0.0239,  0.0168,  0.0302, -0.0247, -0.0211,
        -0.0135, -0.0083, -0.0105,  0.0299, -0.0248, -0.0008, -0.0136,  0.0046,
        -0.0191,  0.0203,  0.0193,  0.0090,  0.0270, -0.0215,  0.0129, -0.0019,
        -0.0002, -0.0014,  0.0067,  0.0087, -0.0140,  0.0228,  0.0044,  0.0221,
        -0.0013,  0.0290,  0.0111,  0.0014,  0.0174, -0.0139,  0.0211, -0.0092,
         0.0022,  0.0113, -0.0209,  0.0167,  0.0082, -0.0005, -0.0028, -0.0311,
         0.0311,  0.0191,  0.0041,  0.0256,  0.0183,  0.0104,  0.0083, -0.0169,
         0.0131,  0.0226, -0.0251, -0.0022, -0.0101,  0.0164, -0.0184,  0.0275],
       device='cuda:0', requires_grad=True)
vlad_layer.FC_2.weight Parameter containing:
tensor([[-0.0013, -0.0013,  0.0015,  ...,  0.0018, -0.0015,  0.0003],
        [ 0.0027, -0.0024,  0.0023,  ..., -0.0033,  0.0032,  0.0016],
        [-0.0016,  0.0002, -0.0032,  ...,  0.0037,  0.0015, -0.0031],
        ...,
        [ 0.0009,  0.0006,  0.0001,  ..., -0.0038, -0.0033,  0.0027],
        [-0.0039,  0.0039, -0.0027,  ...,  0.0007,  0.0035, -0.0007],
        [ 0.0013,  0.0019,  0.0007,  ...,  0.0030,  0.0025,  0.0004]],
       device='cuda:0', requires_grad=True)
vlad_layer.FC_2.bias Parameter containing:
tensor([ 9.3597e-04,  2.4782e-03,  2.1683e-03, -2.8187e-03,  1.3213e-03,
        -3.8050e-04,  3.8459e-03,  1.0257e-03,  4.7719e-04,  1.8287e-03,
         3.7767e-03,  2.8583e-03, -2.3306e-03,  1.7064e-03,  1.7896e-03,
        -2.6085e-03, -3.3905e-03, -3.1106e-03,  3.6587e-04,  2.0456e-03,
         3.1196e-03,  1.2649e-03,  1.0852e-03,  1.2801e-03, -2.3455e-03,
        -1.6145e-03,  1.9547e-03, -1.0697e-03,  8.1978e-04, -3.8935e-03,
         1.9740e-03, -2.4370e-03, -7.7092e-04,  2.2913e-03, -3.7600e-04,
        -2.7490e-03, -1.6656e-03, -3.8446e-03, -1.6749e-03,  6.4329e-04,
        -3.8669e-03, -2.0670e-03,  3.0306e-04, -2.7388e-03, -1.7962e-03,
         1.1506e-03,  2.3498e-03,  6.8959e-04, -1.9909e-03,  2.5715e-03,
        -3.5667e-04, -1.7400e-03, -2.8883e-03,  8.7905e-04,  2.0332e-03,
         2.2283e-04,  1.3901e-03, -4.5055e-04,  7.7639e-04, -1.1104e-03,
         2.6596e-03, -1.2441e-03,  2.2946e-03, -1.5241e-03, -3.6097e-03,
        -1.6350e-03,  1.0449e-03, -3.1088e-03,  5.5218e-04,  1.6405e-03,
        -1.2190e-03,  2.0361e-03,  6.3268e-05, -2.9916e-03,  2.8460e-03,
        -2.9325e-03,  1.5931e-03, -3.0972e-03, -2.0344e-03,  1.1563e-03,
        -5.1439e-05,  2.6436e-03,  1.0824e-03,  2.8074e-04,  3.3089e-03,
        -3.0323e-03,  2.8931e-03, -1.0166e-03,  2.9625e-03,  5.7118e-06,
         8.4730e-05,  1.8704e-03,  1.3317e-05,  1.5571e-03, -3.1028e-03,
         1.0287e-03,  8.0376e-04, -3.5678e-03, -2.1722e-03, -2.9000e-04,
        -2.0175e-03,  2.0466e-05,  3.6352e-03,  3.2404e-03,  7.5584e-04,
        -5.4498e-04,  3.2008e-03, -3.3671e-03, -1.7223e-03, -3.1647e-03,
        -3.1123e-03, -3.0639e-03, -3.4213e-03,  5.0471e-04,  3.3515e-03,
        -2.3568e-03, -5.8874e-04, -1.8689e-03, -4.9260e-04,  3.3771e-03,
        -3.6968e-03,  3.0409e-03,  7.4726e-04, -3.3546e-03, -3.6366e-03,
         3.7617e-03, -2.2805e-03,  2.5156e-04, -1.1862e-03,  1.3628e-03,
        -2.0990e-03,  3.7018e-03,  2.0534e-03,  1.3969e-03, -2.8656e-03,
        -7.4428e-04,  2.9936e-03, -2.0475e-03, -1.9656e-03,  3.7795e-03,
        -3.4141e-03,  3.3250e-03,  3.4973e-03, -3.4292e-03,  6.0744e-04,
         1.7138e-03, -1.3237e-03,  1.0209e-03,  6.4286e-04,  2.6727e-03,
        -1.2433e-03, -1.9592e-03,  2.4463e-03,  1.1123e-03,  2.0069e-03,
         1.1381e-03,  3.8434e-03, -1.7269e-03, -2.2275e-03, -2.8533e-03,
        -1.8965e-03, -9.0586e-04,  2.3055e-03, -2.8807e-03,  3.5268e-03,
         1.1514e-03, -1.1500e-03,  4.6314e-04,  2.4544e-03,  1.8451e-03,
        -2.3917e-03, -3.5494e-03, -1.8997e-03,  1.6117e-03, -1.9100e-03,
         2.1776e-03, -1.7660e-03, -5.4882e-04,  3.0714e-03,  2.6595e-03,
         9.3195e-04, -2.9197e-03, -3.0152e-03,  1.7561e-04, -2.9451e-03,
         3.8747e-03, -6.1225e-04, -1.8505e-04, -2.9209e-03, -3.4568e-03,
        -3.3140e-03, -2.7170e-03, -3.4825e-03, -3.3659e-04, -3.2007e-04,
        -3.0318e-03,  3.5318e-04,  2.5955e-03,  1.8741e-03, -8.3563e-04,
         5.2652e-04, -1.6446e-03, -3.6837e-03,  3.6254e-03, -3.1051e-03,
        -4.3118e-04,  2.7279e-03, -1.1599e-03,  5.7961e-04, -4.8019e-04,
         2.7806e-03,  2.4435e-03,  1.8472e-03,  1.6545e-03,  1.4611e-03,
        -1.6826e-03, -5.5296e-04,  5.7965e-04,  2.0257e-03, -2.4480e-03,
         3.7849e-03, -9.7592e-05, -4.0749e-04, -5.2170e-04, -2.1254e-03,
        -1.1049e-03,  8.7168e-04,  1.7818e-03, -2.1563e-04, -3.4193e-03,
        -2.6109e-03, -3.7887e-03,  2.6010e-04,  2.0385e-03,  3.2503e-03,
        -1.6374e-03, -3.3891e-03,  3.7329e-03, -2.0320e-03,  2.8104e-03,
         1.2554e-03,  9.1385e-04,  1.3562e-03, -2.7410e-03, -3.2025e-03,
        -3.5702e-03,  1.9169e-03, -3.8603e-03,  3.8940e-03,  2.2727e-03,
        -1.9620e-03, -1.9353e-03, -1.9066e-03,  2.6274e-03,  3.4900e-03,
         3.4101e-04], device='cuda:0', requires_grad=True)
<generator object Module.named_parameters at 0x7fde3e1e3970>



Initialize workers
num_centers = 660
epoch_inds: tensor([ 99,  61, 136,  80, 192,  39,  26, 119, 173, 116, 180, 146, 189,  32,
         19, 148,  75, 203, 124,  83, 155,  91, 129,   7,  82, 159,  12, 182,
         28, 100, 102, 127, 154, 113,  93,  45,  95,  87, 161,  37, 151, 198,
         58, 138,  38,  36, 188, 152, 168,   0, 193, 110,  60,  92,  27,  35,
         52, 134,  71, 106,   5,  46,  29,  76, 175,  20,  97,  56, 197, 157,
        150,  63,  74, 104, 194, 137, 147, 174, 202, 143, 164, 142, 130, 171,
         42, 178,  64,   3,  30,  84,   2,  94,  96,  14, 101, 200,  22,  72,
        105,  34,  15, 118,  41,  90,   9, 177, 169,  50,   4, 115, 165, 162,
        196,  77,  81, 166,  55, 125, 176,  23,  43,  78, 167, 128,  53, 121,
        131, 158, 183,  47,   8, 103, 132,  86,  62, 185,  85,  98, 149, 170,
        186, 179,  18, 139, 123,  59,  13, 120, 163,  67, 141, 201, 187, 195,
        112,  49, 117,  33,  16,  21, 184,  51,  89, 107,  70,  31, 145,  68,
        199, 108,  73,  11,  88,  24, 126, 190, 122,  66,   1, 160,  25, 181,
        135, 140,  69,  17,  44, 191, 153,  40, 114,  57,  10, 133, 111, 144,
        172,  65,   6,  79,  48, 109,  54, 156,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1])
e000-i0000 => L=0.8672
Skip current pcd ( scene0001_00_500.ply ) due to empty positives.
e000-i0002 => L=0.0000
e000-i0003 => L=0.9683
Skip current pcd ( scene0191_00_300.ply ) due to empty positives.
e000-i0005 => L=0.9287
e000-i0006 => L=0.9702
e000-i0007 => L=0.8023
e000-i0008 => L=0.8539
e000-i0009 => L=0.7921
e000-i0010 => L=0.3928
e000-i0011 => L=0.7628
e000-i0012 => L=0.7293
e000-i0013 => L=1.0351
e000-i0014 => L=0.8801
Skip current pcd ( scene0069_00_100.ply ) due to empty positives.
e000-i0016 => L=1.1344
Skip current pcd ( scene0230_00_300.ply ) due to empty positives.
e000-i0018 => L=0.9840
e000-i0019 => L=1.0527
e000-i0020 => L=0.9333
e000-i0021 => L=0.9613
e000-i0022 => L=0.9742
e000-i0023 => L=0.9569
e000-i0024 => L=0.9940
e000-i0025 => L=0.9408
e000-i0026 => L=0.9076
e000-i0027 => L=0.8844
e000-i0028 => L=0.9520
e000-i0029 => L=0.8769
e000-i0030 => L=1.0187
e000-i0031 => L=0.9529
e000-i0032 => L=0.9529
e000-i0033 => L=0.9304
e000-i0034 => L=0.9661
e000-i0035 => L=0.9709
e000-i0036 => L=1.0539
e000-i0037 => L=0.9118
e000-i0038 => L=0.9605
e000-i0039 => L=0.9247
e000-i0040 => L=0.9316
e000-i0041 => L=0.9908
Skip current pcd ( scene0001_00_200.ply ) due to empty positives.
e000-i0043 => L=0.9117
e000-i0044 => L=0.8730
e000-i0045 => L=0.9627
e000-i0046 => L=0.8913
e000-i0047 => L=1.0002
e000-i0048 => L=0.9224
e000-i0049 => L=0.9239
e000-i0050 => L=0.9983
e000-i0051 => L=0.9953
e000-i0052 => L=0.8447
e000-i0053 => L=0.8827
e000-i0054 => L=0.8317
e000-i0055 => L=1.0558
e000-i0056 => L=0.9363
e000-i0057 => L=0.8329
e000-i0058 => L=0.9965
e000-i0059 => L=0.9948
e000-i0060 => L=0.9327
e000-i0061 => L=0.8832
e000-i0062 => L=0.9247
e000-i0063 => L=0.9363
e000-i0064 => L=1.0333
e000-i0065 => L=0.8722
e000-i0066 => L=0.9345
e000-i0067 => L=1.0008
e000-i0068 => L=0.9481
e000-i0069 => L=0.9481
e000-i0070 => L=0.9299
e000-i0071 => L=0.9446
e000-i0072 => L=0.9053
e000-i0073 => L=0.9920
Skip current pcd ( scene0191_00_500.ply ) due to empty positives.
e000-i0075 => L=0.8938
Skip current pcd ( scene0069_00_0.ply ) due to empty positives.
e000-i0077 => L=0.9250
Skip current pcd ( scene0230_00_200.ply ) due to empty positives.
e000-i0079 => L=0.8348
e000-i0080 => L=0.8364
e000-i0081 => L=0.7991
e000-i0082 => L=1.0345
e000-i0083 => L=0.8051
e000-i0084 => L=0.9933
e000-i0085 => L=0.7926
e000-i0086 => L=1.0108
e000-i0087 => L=0.8646
e000-i0088 => L=1.0598
e000-i0089 => L=0.7879
e000-i0090 => L=0.8192
e000-i0091 => L=0.8136
e000-i0092 => L=0.8651
e000-i0093 => L=0.9107
e000-i0094 => L=0.8160
Skip current pcd ( scene0230_00_0.ply ) due to empty positives.
e000-i0096 => L=0.8390
e000-i0097 => L=0.7585
e000-i0098 => L=1.0510
e000-i0099 => L=0.8899
e000-i0100 => L=1.0091
e000-i0101 => L=0.7656
e000-i0102 => L=0.9620
e000-i0103 => L=0.7503
e000-i0104 => L=0.9968
e000-i0105 => L=0.9769
e000-i0106 => L=0.6953
e000-i0107 => L=0.9052
e000-i0108 => L=0.7805
e000-i0109 => L=0.9746
e000-i0110 => L=0.8651
e000-i0111 => L=0.8482
e000-i0112 => L=0.9688
e000-i0113 => L=0.9315
e000-i0114 => L=0.9628
e000-i0115 => L=0.7876
e000-i0116 => L=0.7686
e000-i0117 => L=1.0460
e000-i0118 => L=0.6856
e000-i0119 => L=0.8909
e000-i0120 => L=0.8806
e000-i0121 => L=0.9120
e000-i0122 => L=0.8765
e000-i0123 => L=0.6674
e000-i0124 => L=0.9012
e000-i0125 => L=0.7668
e000-i0126 => L=1.0367
e000-i0127 => L=0.9662
e000-i0128 => L=0.7594
e000-i0129 => L=1.1340
e000-i0130 => L=0.9211
e000-i0131 => L=0.8125
e000-i0132 => L=0.9529
e000-i0133 => L=0.4597
e000-i0134 => L=0.8070
e000-i0135 => L=0.6157
e000-i0136 => L=0.8636
e000-i0137 => L=0.7297
Skip current pcd ( scene0069_00_200.ply ) due to empty positives.
e000-i0139 => L=0.8537
e000-i0140 => L=1.0094
e000-i0141 => L=0.9171
e000-i0142 => L=0.8042
e000-i0143 => L=0.6257
e000-i0144 => L=0.6388
e000-i0145 => L=0.9365
e000-i0146 => L=0.6659
e000-i0147 => L=1.0259
e000-i0148 => L=0.7174
e000-i0149 => L=1.0069
e000-i0150 => L=0.4205
Skip current pcd ( scene0230_00_100.ply ) due to empty positives.
e000-i0152 => L=0.4924
e000-i0153 => L=0.9627
e000-i0154 => L=0.9096
e000-i0155 => L=0.8967
e000-i0156 => L=1.2323
e000-i0157 => L=0.7943
e000-i0158 => L=0.7152
e000-i0159 => L=0.7868
e000-i0160 => L=0.4923
e000-i0161 => L=0.8895
e000-i0162 => L=0.7226
e000-i0163 => L=0.7803
e000-i0164 => L=1.0003
e000-i0165 => L=0.7045
e000-i0166 => L=0.7150
e000-i0167 => L=0.9781
e000-i0168 => L=0.7780
e000-i0169 => L=0.8587
e000-i0170 => L=0.7920
e000-i0171 => L=0.8306
e000-i0172 => L=0.6382
e000-i0173 => L=0.6463
e000-i0174 => L=0.8225
e000-i0175 => L=0.4654
e000-i0176 => L=0.8986
e000-i0177 => L=1.1268
e000-i0178 => L=0.8539
e000-i0179 => L=1.1373
e000-i0180 => L=1.0331
e000-i0181 => L=1.0357
e000-i0182 => L=0.3165
e000-i0183 => L=0.4174
e000-i0184 => L=0.8850
e000-i0185 => L=0.8393
e000-i0186 => L=0.5725
Skip current pcd ( scene0191_00_200.ply ) due to empty positives.
e000-i0188 => L=0.5466
e000-i0189 => L=0.8331
e000-i0190 => L=1.0964
e000-i0191 => L=0.4428
e000-i0192 => L=1.0655
e000-i0193 => L=0.6757
e000-i0194 => L=0.9399
e000-i0195 => L=0.3007
e000-i0196 => L=1.3392
e000-i0197 => L=0.3378
e000-i0198 => L=0.7366
e000-i0199 => L=1.4620
e000-i0200 => L=1.0187
e000-i0201 => L=1.0892
e000-i0202 => L=0.5997
e000-i0203 => L=0.6903
Current epoch 0 finished.
num_centers = 660
epoch_inds: tensor([ 98,  67,  60, 190,  88,  62,  77, 121, 119, 167, 140,  75, 101, 150,
        200, 129,  73,  17,  57, 112, 176, 109, 107,  74,  94,  29,  15,   6,
        148, 120,  39,  48,  82,  37,  71, 153, 171,   4,   8, 174,  97,  58,
        177, 188, 184,  61,  85,  16, 130, 160, 142, 162, 199, 145,  10,   0,
        181,  14, 147, 170,   1, 186, 131, 202, 182,  25, 141, 102, 146, 135,
         23,  79,  27, 103, 134, 179, 100, 191, 105, 159,  99, 108, 158,  92,
         21, 116, 127,  87, 161, 156, 201,  12, 104,  63,  38, 126, 163,  43,
         93, 178, 133,  81, 155, 193, 169,   2,  55, 136,  34, 117,  95,  59,
         28,  86,  78, 198,  66,  18, 137,  49, 139, 166,  22,  35, 172,  36,
         45, 164, 138, 115, 144, 175,  65, 194,  91,  42, 106,  84, 113,  26,
         33,  11,  64, 192, 132, 122, 111,  32, 124, 195,  76, 173,  41,  50,
         46, 154,  44,  80, 149,  70,  90,   3,  30, 118, 125,  53, 187, 183,
         54, 152, 114, 180, 203,  56, 151, 128,  40, 157,  13,  52,  68, 168,
          9,   7, 123, 165, 196,  69,  72,  19, 110, 185, 197,  83,  96, 143,
         24,  47,  51,  89,   5, 189,  31,  20,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1])
e001-i0000 => L=0.2495
e001-i0001 => L=0.1994
e001-i0002 => L=0.4667
e001-i0003 => L=0.9263
e001-i0004 => L=0.5003
e001-i0005 => L=0.8396
e001-i0006 => L=1.2490
e001-i0007 => L=1.1164
e001-i0008 => L=0.8548
e001-i0009 => L=0.6581
e001-i0010 => L=0.3720
e001-i0011 => L=0.9002
e001-i0012 => L=0.5173
e001-i0013 => L=0.7238
Skip current pcd ( scene0230_00_0.ply ) due to empty positives.
e001-i0015 => L=0.5632
e001-i0016 => L=0.5754
e001-i0017 => L=0.8394
e001-i0018 => L=0.5136
e001-i0019 => L=0.8535
e001-i0020 => L=0.5056
e001-i0021 => L=0.7503
e001-i0022 => L=0.6255
e001-i0023 => L=0.3936
e001-i0024 => L=0.6459
e001-i0025 => L=0.7944
e001-i0026 => L=0.8743
e001-i0027 => L=1.2782
Skip current pcd ( scene0069_00_100.ply ) due to empty positives.
e001-i0029 => L=0.4030
e001-i0030 => L=0.9644
e001-i0031 => L=0.8092
e001-i0032 => L=0.0510
e001-i0033 => L=0.5761
e001-i0034 => L=1.0924
e001-i0035 => L=0.8998
e001-i0036 => L=0.4355
e001-i0037 => L=0.5123
e001-i0038 => L=0.7393
e001-i0039 => L=0.5068
e001-i0040 => L=0.1545
Skip current pcd ( scene0001_00_200.ply ) due to empty positives.
e001-i0042 => L=0.8886
e001-i0043 => L=0.9645
e001-i0044 => L=0.1854
Skip current pcd ( scene0001_00_500.ply ) due to empty positives.
e001-i0046 => L=0.1816
e001-i0047 => L=0.4074
e001-i0048 => L=0.5924
e001-i0049 => L=1.2524
e001-i0050 => L=0.4672
e001-i0051 => L=0.8632
e001-i0052 => L=0.5244
e001-i0053 => L=0.4296
e001-i0054 => L=0.9506
e001-i0055 => L=0.3377
e001-i0056 => L=1.1297
e001-i0057 => L=1.4334
Skip current pcd ( scene0069_00_0.ply ) due to empty positives.
e001-i0059 => L=0.4671
e001-i0060 => L=0.9468
e001-i0061 => L=1.4413
e001-i0062 => L=0.7387
Skip current pcd ( scene0230_00_200.ply ) due to empty positives.
e001-i0064 => L=0.5808
e001-i0065 => L=1.3084
e001-i0066 => L=0.5915
e001-i0067 => L=0.6120
e001-i0068 => L=0.4486
e001-i0069 => L=0.5595
e001-i0070 => L=0.2504
e001-i0071 => L=0.5301
e001-i0072 => L=0.5769
e001-i0073 => L=0.5186
e001-i0074 => L=0.5888
e001-i0075 => L=0.4705
e001-i0076 => L=0.6604
Skip current pcd ( scene0191_00_200.ply ) due to empty positives.
e001-i0078 => L=0.2663
e001-i0079 => L=0.8508
e001-i0080 => L=0.9261
e001-i0081 => L=0.2749
e001-i0082 => L=0.4042
e001-i0083 => L=0.3398
e001-i0084 => L=0.6710
e001-i0085 => L=0.7409
e001-i0086 => L=0.8952
e001-i0087 => L=1.0394
e001-i0088 => L=0.0186
e001-i0089 => L=0.2195
Skip current pcd ( scene0230_00_100.ply ) due to empty positives.
e001-i0091 => L=0.3217
e001-i0092 => L=0.6275
e001-i0093 => L=0.6846
e001-i0094 => L=0.5542
e001-i0095 => L=0.5472
e001-i0096 => L=0.4726
e001-i0097 => L=0.6398
e001-i0098 => L=0.1743
e001-i0099 => L=0.5944
e001-i0100 => L=0.0002
e001-i0101 => L=1.5603
e001-i0102 => L=0.3446
e001-i0103 => L=0.4383
e001-i0104 => L=0.0000
e001-i0105 => L=0.1308
e001-i0106 => L=0.0991
e001-i0107 => L=0.1764
e001-i0108 => L=0.6580
e001-i0109 => L=1.3413
e001-i0110 => L=0.4769
e001-i0111 => L=0.0394
e001-i0112 => L=1.7041
e001-i0113 => L=0.7272
e001-i0114 => L=1.1744
e001-i0115 => L=1.4789
e001-i0116 => L=0.6150
e001-i0117 => L=0.9225
e001-i0118 => L=0.6512
e001-i0119 => L=0.8012
e001-i0120 => L=0.8049
e001-i0121 => L=0.7366
e001-i0122 => L=0.7114
e001-i0123 => L=1.5558
e001-i0124 => L=0.8862
e001-i0125 => L=0.6658
e001-i0126 => L=0.2178
e001-i0127 => L=0.2872
e001-i0128 => L=0.2699
e001-i0129 => L=1.6836
e001-i0130 => L=0.4227
e001-i0131 => L=0.4284
e001-i0132 => L=0.5335
Skip current pcd ( scene0191_00_500.ply ) due to empty positives.
e001-i0134 => L=0.3467
e001-i0135 => L=0.7393
e001-i0136 => L=0.9400
e001-i0137 => L=0.0719
e001-i0138 => L=0.6454
e001-i0139 => L=0.4109
e001-i0140 => L=0.7497
e001-i0141 => L=0.6319
e001-i0142 => L=1.1161
Skip current pcd ( scene0191_00_300.ply ) due to empty positives.
e001-i0144 => L=0.1314
e001-i0145 => L=0.2552
e001-i0146 => L=0.9961
e001-i0147 => L=0.5706
e001-i0148 => L=0.5984
e001-i0149 => L=0.7112
e001-i0150 => L=0.9030
e001-i0151 => L=0.1947
e001-i0152 => L=0.9064
e001-i0153 => L=0.4533
e001-i0154 => L=0.6701
e001-i0155 => L=0.5199
e001-i0156 => L=0.7366
e001-i0157 => L=1.0681
Skip current pcd ( scene0069_00_200.ply ) due to empty positives.
e001-i0159 => L=0.5388
e001-i0160 => L=0.7144
e001-i0161 => L=0.4807
e001-i0162 => L=1.0902
e001-i0163 => L=0.1737
e001-i0164 => L=0.7154
e001-i0165 => L=0.9729
e001-i0166 => L=0.2186
e001-i0167 => L=0.6529
e001-i0168 => L=0.2269
e001-i0169 => L=0.5710
e001-i0170 => L=1.1729
e001-i0171 => L=0.4812
Skip current pcd ( scene0230_00_300.ply ) due to empty positives.
e001-i0173 => L=0.6484
e001-i0174 => L=0.9266
e001-i0175 => L=0.0290
e001-i0176 => L=1.3205
e001-i0177 => L=0.3046
e001-i0178 => L=0.5402
e001-i0179 => L=0.6804
e001-i0180 => L=0.5576
e001-i0181 => L=0.2198
e001-i0182 => L=0.5405
e001-i0183 => L=0.3979
e001-i0184 => L=0.0022
e001-i0185 => L=0.7560
e001-i0186 => L=0.6684
e001-i0187 => L=1.2667
e001-i0188 => L=0.4436
e001-i0189 => L=0.7281
e001-i0190 => L=0.0871
e001-i0191 => L=0.5232
e001-i0192 => L=0.4301
e001-i0193 => L=0.9093
e001-i0194 => L=0.3272
e001-i0195 => L=0.3889
e001-i0196 => L=0.3478
e001-i0197 => L=0.3461
e001-i0198 => L=0.7554
e001-i0199 => L=0.7542
e001-i0200 => L=0.0406
e001-i0201 => L=0.2888
e001-i0202 => L=0.4623
e001-i0203 => L=0.3675
Current epoch 1 finished.
num_centers = 660
epoch_inds: tensor([105,  34,  59,  22, 116,  31,  77, 157,  14,  16,  35, 190, 137,  62,
          8,  41,  23, 199, 117, 142, 174, 121, 196, 146, 183, 166, 108,  64,
         60,  80, 104,   4,  30,  11, 125,  48, 178, 123,  65, 195,  39, 173,
        188, 112,  15, 118,  26, 122, 171, 132, 119, 149, 107,  57,  87,  10,
        140,  42, 136, 101,  52,  21, 201, 143,  93, 197,  79, 163,  55, 127,
         37, 134,  83,  25,  78, 165,  86, 133,  81,   3, 155, 162, 203, 154,
        177, 103,   6,  99,  43,  94, 128,  70, 193, 158,  88, 124,  46, 176,
        145,  36, 106, 156, 126, 194,  84, 131, 151, 120,   0,  27, 144,  29,
        179,  44,  72, 150, 141, 187, 148,  96, 159,  32, 161,  75,  98,   9,
         68,  85,  66, 170,  73,  95,  49, 182,  92,  53,  71, 130, 169,  38,
         40, 152,   2, 180,  18, 175,  33, 153, 114,   5,  24,  28, 189,  69,
        200,  82, 138,  63,  89,  20,  61, 186,  90,  58, 191, 192, 135,  45,
        102, 198,  54, 164,  97,  13,  74, 129,  56,   7, 181,  76,  12, 147,
        185, 100,  67,  17, 172, 111, 202, 115, 167, 184, 113,  91,  51,   1,
        110,  19,  47, 168,  50, 109, 160, 139,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1])
e002-i0000 => L=0.0000
e002-i0001 => L=0.1764
e002-i0002 => L=0.3411
e002-i0003 => L=0.5165
e002-i0004 => L=0.4187
e002-i0005 => L=0.4778
e002-i0006 => L=0.5410
e002-i0007 => L=0.1982
e002-i0008 => L=0.0710
e002-i0009 => L=0.6056
e002-i0010 => L=0.2847
e002-i0011 => L=0.9039
e002-i0012 => L=0.4478
e002-i0013 => L=0.3933
e002-i0014 => L=0.4621
e002-i0015 => L=0.9200
e002-i0016 => L=0.2661
e002-i0017 => L=0.5413
e002-i0018 => L=0.1739
e002-i0019 => L=0.4012
e002-i0020 => L=0.2577
e002-i0021 => L=0.1555
e002-i0022 => L=0.8504
e002-i0023 => L=0.4390
e002-i0024 => L=0.2202
e002-i0025 => L=0.4166
e002-i0026 => L=0.5192
e002-i0027 => L=0.7759
e002-i0028 => L=0.5775
e002-i0029 => L=0.5819
e002-i0030 => L=0.2731
e002-i0031 => L=0.2104
e002-i0032 => L=0.5085
e002-i0033 => L=0.3140
e002-i0034 => L=0.2492
e002-i0035 => L=0.8978
e002-i0036 => L=0.0101
e002-i0037 => L=0.2668
e002-i0038 => L=0.1939
e002-i0039 => L=0.6552
e002-i0040 => L=0.4294
e002-i0041 => L=0.3869
e002-i0042 => L=0.4384
e002-i0043 => L=0.4611
e002-i0044 => L=0.4777
e002-i0045 => L=0.5985
e002-i0046 => L=0.3495
e002-i0047 => L=0.5621
e002-i0048 => L=0.1791
e002-i0049 => L=1.0032
e002-i0050 => L=0.4252
Skip current pcd ( scene0069_00_200.ply ) due to empty positives.
e002-i0052 => L=0.3723
e002-i0053 => L=0.8112
e002-i0054 => L=0.2283
e002-i0055 => L=0.8862
e002-i0056 => L=0.0344
e002-i0057 => L=0.4830
e002-i0058 => L=0.0000
e002-i0059 => L=0.7384
e002-i0060 => L=0.1024
e002-i0061 => L=0.7612
Skip current pcd ( scene0230_00_100.ply ) due to empty positives.
e002-i0063 => L=0.0513
e002-i0064 => L=0.4801
e002-i0065 => L=0.7747
e002-i0066 => L=0.9495
e002-i0067 => L=0.2671
e002-i0068 => L=0.3222
e002-i0069 => L=0.5449
e002-i0070 => L=0.6617
e002-i0071 => L=0.3220
e002-i0072 => L=1.3264
e002-i0073 => L=0.2740
e002-i0074 => L=0.9989
e002-i0075 => L=0.3341
e002-i0076 => L=0.7161
e002-i0077 => L=0.5851
e002-i0078 => L=0.5333
e002-i0079 => L=0.9013
e002-i0080 => L=0.8967
e002-i0081 => L=0.3799
Skip current pcd ( scene0230_00_300.ply ) due to empty positives.
e002-i0083 => L=0.8206
e002-i0084 => L=0.9187
e002-i0085 => L=0.7984
e002-i0086 => L=0.5305
e002-i0087 => L=0.7425
e002-i0088 => L=0.8615
e002-i0089 => L=0.9153
e002-i0090 => L=0.3232
e002-i0091 => L=0.4572
e002-i0092 => L=0.6699
e002-i0093 => L=0.7748
e002-i0094 => L=0.1285
e002-i0095 => L=0.4707
e002-i0096 => L=0.4555
e002-i0097 => L=0.6393
e002-i0098 => L=0.1249
e002-i0099 => L=0.4924
e002-i0100 => L=0.2314
e002-i0101 => L=0.5638
e002-i0102 => L=0.8306
Skip current pcd ( scene0191_00_500.ply ) due to empty positives.
e002-i0104 => L=0.2382
e002-i0105 => L=0.2236
e002-i0106 => L=0.6410
e002-i0107 => L=0.8990
e002-i0108 => L=0.1755
e002-i0109 => L=0.4425
e002-i0110 => L=0.7488
e002-i0111 => L=0.6332
e002-i0112 => L=0.0388
e002-i0113 => L=0.7034
e002-i0114 => L=0.7655
e002-i0115 => L=0.6089
e002-i0116 => L=0.8763
e002-i0117 => L=0.5582
Skip current pcd ( scene0069_00_100.ply ) due to empty positives.
e002-i0119 => L=0.2001
e002-i0120 => L=0.7371
e002-i0121 => L=0.4647
e002-i0122 => L=0.6540
e002-i0123 => L=1.8232
e002-i0124 => L=0.6759
e002-i0125 => L=1.1207
e002-i0126 => L=1.3247
e002-i0127 => L=0.0000
e002-i0128 => L=1.3768
e002-i0129 => L=0.7589
e002-i0130 => L=0.1236
e002-i0131 => L=0.1007
e002-i0132 => L=0.4933
e002-i0133 => L=0.4522
e002-i0134 => L=0.4634
e002-i0135 => L=0.1525
e002-i0136 => L=0.2155
e002-i0137 => L=0.3529
e002-i0138 => L=0.3326
e002-i0139 => L=0.6425
e002-i0140 => L=0.0605
e002-i0141 => L=0.4483
e002-i0142 => L=0.8497
e002-i0143 => L=0.4111
e002-i0144 => L=0.4880
e002-i0145 => L=0.2706
e002-i0146 => L=0.8679
e002-i0147 => L=0.3821
e002-i0148 => L=0.6818
e002-i0149 => L=0.2636
e002-i0150 => L=0.3030
e002-i0151 => L=0.7237
e002-i0152 => L=0.3936
e002-i0153 => L=0.8627
Skip current pcd ( scene0230_00_0.ply ) due to empty positives.
e002-i0155 => L=1.1343
e002-i0156 => L=0.2277
e002-i0157 => L=0.6170
e002-i0158 => L=0.7006
e002-i0159 => L=0.1520
Skip current pcd ( scene0001_00_500.ply ) due to empty positives.
e002-i0161 => L=0.4871
e002-i0162 => L=0.6845
Skip current pcd ( scene0001_00_200.ply ) due to empty positives.
Skip current pcd ( scene0191_00_200.ply ) due to empty positives.
Skip current pcd ( scene0191_00_300.ply ) due to empty positives.
e002-i0166 => L=0.4972
e002-i0167 => L=0.4471
e002-i0168 => L=0.4987
e002-i0169 => L=0.6682
e002-i0170 => L=0.8511
e002-i0171 => L=0.1935
e002-i0172 => L=0.1022
e002-i0173 => L=0.4979
e002-i0174 => L=0.6007
e002-i0175 => L=0.4644
e002-i0176 => L=0.3800
e002-i0177 => L=0.3022
e002-i0178 => L=0.4372
e002-i0179 => L=1.1564
e002-i0180 => L=0.7453
Skip current pcd ( scene0069_00_0.ply ) due to empty positives.
e002-i0182 => L=0.7639
e002-i0183 => L=0.0354
e002-i0184 => L=0.4234
e002-i0185 => L=0.4586
e002-i0186 => L=0.5612
e002-i0187 => L=0.4713
Skip current pcd ( scene0230_00_200.ply ) due to empty positives.
e002-i0189 => L=1.0530
e002-i0190 => L=0.1513
e002-i0191 => L=0.7833
e002-i0192 => L=1.5761
e002-i0193 => L=0.0000
e002-i0194 => L=0.5340
e002-i0195 => L=0.2337
e002-i0196 => L=1.4391
e002-i0197 => L=0.3166
e002-i0198 => L=0.4118
e002-i0199 => L=0.3977
e002-i0200 => L=0.4559
e002-i0201 => L=0.1388
e002-i0202 => L=1.3494
e002-i0203 => L=0.4387
Current epoch 2 finished.
num_centers = 660
epoch_inds: tensor([141,   8,  47,  99,  22, 167, 106, 101, 153, 173,  10, 136,  15, 166,
        103, 148, 155, 164, 147,  77, 197,  84,  31, 174, 180,  98,  34,  27,
        189, 135,  97, 138,  32, 151,  70, 188, 159,  18, 145, 157,  58,  23,
        194,  55, 139,  51, 130, 186, 191, 105, 178,  94, 111,  82, 127, 109,
        169,  29,  64,  37,  79,  63, 144,  87, 200, 198, 146, 181, 122, 203,
         90,  42, 187,  26,  85,  67, 192, 176, 149, 195,  71, 104,  35, 161,
        175,  65,  28, 190,  41,  52,  83,  17,  16, 134,  43,   4,  20, 118,
        202, 114, 112,  50,  59,  49,  95,  75, 125,  62, 124,  96, 201, 163,
        133, 177,  53, 182, 115,   7, 108,  69, 137,  57, 121, 156, 184, 128,
         88, 110,  12,   6,  48,  72,  33, 193, 179,  30,  81,  78,  89, 172,
        140, 160, 162, 116,  80, 165,  92,  86,  73,  19, 102,  56,  21,  14,
         25, 199, 129, 120,   1,   0,  66, 171, 126, 107, 113,   5, 168,  46,
         36,   2, 150,  44, 119, 183,  13,  93,  68, 142, 131, 100,  40,  54,
          9, 143,  91, 117,   3,  24,  61,  76, 158, 185,  74,  45, 123,  11,
        132, 170, 196,  39,  60, 152,  38, 154,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,
         -1,  -1])
e003-i0000 => L=0.8209
e003-i0001 => L=1.1012
e003-i0002 => L=0.2378
e003-i0003 => L=0.8482
e003-i0004 => L=0.4368
e003-i0005 => L=0.6151
e003-i0006 => L=0.4462
e003-i0007 => L=0.3578
e003-i0008 => L=0.5854
e003-i0009 => L=0.4675
e003-i0010 => L=0.8683
e003-i0011 => L=0.3495
e003-i0012 => L=0.5578
e003-i0013 => L=0.2054
e003-i0014 => L=0.0071
Skip current pcd ( scene0069_00_100.ply ) due to empty positives.
e003-i0016 => L=0.1364
e003-i0017 => L=0.2728
Skip current pcd ( scene0069_00_0.ply ) due to empty positives.
e003-i0019 => L=1.0029
e003-i0020 => L=0.5049
e003-i0021 => L=0.2854
e003-i0022 => L=0.2233
e003-i0023 => L=0.4261
e003-i0024 => L=0.7614
e003-i0025 => L=0.2337
e003-i0026 => L=0.4701
e003-i0027 => L=0.7885
e003-i0028 => L=0.5485
e003-i0029 => L=0.3170
e003-i0030 => L=0.4945
e003-i0031 => L=0.7920
e003-i0032 => L=1.2719
e003-i0033 => L=0.3888
e003-i0034 => L=0.6492
e003-i0035 => L=0.4620
e003-i0036 => L=0.7080
e003-i0037 => L=0.6229
e003-i0038 => L=0.0809
e003-i0039 => L=0.2540
Skip current pcd ( scene0001_00_200.ply ) due to empty positives.
e003-i0041 => L=0.4998
Skip current pcd ( scene0191_00_500.ply ) due to empty positives.
e003-i0043 => L=0.6633
e003-i0044 => L=0.7150
e003-i0045 => L=0.7306
e003-i0046 => L=0.0967
e003-i0047 => L=0.2702
Skip current pcd ( scene0191_00_200.ply ) due to empty positives.
e003-i0049 => L=0.4949
e003-i0050 => L=0.0270
e003-i0051 => L=0.4907
e003-i0052 => L=0.4668
e003-i0053 => L=1.0909
e003-i0054 => L=0.2200
e003-i0055 => L=0.6519
e003-i0056 => L=0.0000
Traceback (most recent call last):
  File "feature_embedding_test.py", line 344, in <module>
    loss.backward()
  File "/home/yohann/anaconda3/envs/graph/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yohann/anaconda3/envs/graph/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.59 GiB (GPU 0; 7.80 GiB total capacity; 3.76 GiB already allocated; 1.50 GiB free; 4.35 GiB reserved in total by PyTorch)

